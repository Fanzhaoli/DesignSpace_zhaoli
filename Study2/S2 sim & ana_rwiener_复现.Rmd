---
title: "S2 simulation & analysis"
output: html_document
---

```{r}
# Packages

# you may have to install devtools first with 
# install.packages("devtools")
# devtools::install_github("psyteachr/introdataviz")

if (!requireNamespace('pacman', quietly = TRUE)) {
    install.packages('pacman')
}

pacman::p_load(
  tidyverse, RWiener, introdataviz, lme4, caret, stats4, purrr,
  ggplot2, patchwork, plotly, scatterplot3d, plotrix, akima
  )
install.packages("introdataviz")
# 不使用科学计数法显示
options(scipen = 999)
```

# Simulation
```{r}
generate_ddm_simulations <- function(n_subjects, n_trials_per_subject,
                                     N_range = c(1, 100),
                                     T_range = c(50, 600),
                                     W_range = c(500, 3000)) {
 # 定义实验条件，2*3=6
  conditions <- expand.grid(match = c("match", "mismatch"), 
                            label = c("self", "friend", "stranger"))
  trials_per_condition <- n_trials_per_subject / nrow(conditions)
  
  # 创建空的list存储模拟数据
  simulated_data <- vector("list", n_subjects * n_trials_per_subject)
  idx <- 1  # 用于跟踪存储位置
  
  # 被试循环
  for (subj in 1:n_subjects) {
    # 随机抽取被试层级参数
    N <- sample(N_range[1]:N_range[2], 1)
    T <- sample(T_range[1]:T_range[2], 1)
    W <- sample(W_range[1]:W_range[2], 1)
    
    # 参数归一化：把变量拉到0-1之间
    normalized_N <- (N - N_range[1]) / (N_range[2] - N_range[1])
    normalized_T <- (T - T_range[1]) / (T_range[2] - T_range[1])
    normalized_W <- (W - W_range[1]) / (W_range[2] - W_range[1])
    
    # 条件循环
    for (cond in 1:nrow(conditions)) {
      # 变化参数：v和a按条件计算
      if (conditions$match[cond] == "match") {
        if (conditions$label[cond] == "self") {
          v <- 1.5 * normalized_N + 5.6 * normalized_T - 0.05
          a <- 1.5 * normalized_W + 0.4
        } else if (conditions$label[cond] == "friend") {
          v <- 1.4 * normalized_N + 3.5 * normalized_T - 0.05
          a <- 1.3 * normalized_W + 0.5
        } else {
          v <- 1.3 * normalized_N + 2.7 * normalized_T - 0.05
          a <- 1.4 * normalized_W + 0.6
        }
      } else {
        v <- 1.1 * normalized_N + 1.7 * normalized_T - 0.05
        a <- 1.2 * normalized_W + 0.8
      }
      
      # 固定参数
      z <- 0.5
      t <- 0.5
      
      # 试次循环
      for (trial in 1:trials_per_condition) {
        # 生成单次试验数据
        sim_data <- rwiener(1, a, t, z, v)
        
        # 存储到list
        simulated_data[[idx]] <- data.frame(
          subj_idx = subj, 
          trial_idx = idx,
          rt = sim_data$q, 
          response = sim_data$resp, 
          v = v, a = a, t = t, z = z,
          N = N, T = T, W = W,
          NN = normalized_N, NT = normalized_T, NW = normalized_W,
          matchness = conditions$match[cond], 
          label = conditions$label[cond]
        )
        idx <- idx + 1
      }
    }
  }
  
  # 将list合并为dataframe
  simulated_data <- bind_rows(simulated_data)
  return(simulated_data)
}
```

```{r}
# 假设有100个被试，每个被试完成360个试次，每个条件下各60个试次
if (!require(RWiener)) {
  install.packages("RWiener")
  library(RWiener)
}
set.seed(032)
n_subjects <- 100
n_trials_per_subject <- 360

simulated_ddm_data <- generate_ddm_simulations(n_subjects, n_trials_per_subject)
```

```{r}
simulated_ddm_data
```

# Optimization
```{r}
# 分段
generate_ddm_simulations_optimized <- function(n_subjects, n_trials_per_subject,
                                               N_range = c(1, 100),
                                               T_range = c(50, 600),
                                               W_range = c(500, 3000)) {
  # 定义实验条件
  conditions <- expand.grid(match = c("match", "mismatch"), 
                            label = c("self", "friend", "stranger"))
  trials_per_condition <- n_trials_per_subject / nrow(conditions)
  
  # 创建空的list存储模拟数据
  simulated_data <- vector("list", n_subjects * n_trials_per_subject)
  idx <- 1  # 用于跟踪存储位置
  
  # 被试循环
  for (subj in 1:n_subjects) {
    # 随机抽取被试层级参数
    N <- sample(N_range[1]:N_range[2], 1)
    T <- sample(T_range[1]:T_range[2], 1)
    W <- sample(W_range[1]:W_range[2], 1)
    
    # 参数归一化
    normalized_N <- (N - N_range[1]) / (N_range[2] - N_range[1])
    normalized_T <- (T - T_range[1]) / (T_range[2] - T_range[1])
    normalized_W <- (W - W_range[1]) / (W_range[2] - W_range[1])
    
    # 条件循环
    for (cond in 1:nrow(conditions)) {
      # 优化1:初始化 v 和 a（避免跳过赋值）
      v <- 0
      a <- 0
      
      if (conditions$match[cond] == "match") {
        if (conditions$label[cond] == "self") {
          # 优化2：v的“非线性约束”（模拟真实决策：不会无限制增长）
          # 处理 v：N > 20 和 W > 1800 时增长减缓甚至下降
          if (N > 20 && W > 1800) {
            v <- 1.5 * log(1 + normalized_N) + 5.6 * normalized_T - 0.2 * normalized_N * normalized_W - 0.05
          } else {
            v <- 1.5 * normalized_N + 5.6 * normalized_T - 0.05
          }
          # 优化3：a的“区间约束”（模拟决策谨慎度的“最佳区间”）
          # 处理 a：W 在 1100-1500 时最佳
          if (W < 1100) {
            a <- 1.2 * normalized_W + 0.6  # 激进
          } else if (W > 1500) {
            a <- 1.2 * normalized_W - 0.2  # 保守
          } else {
            a <- 1.5  # 最佳水平
          }
        } else if (conditions$label[cond] == "friend") {
          
          v <- 1.4 * normalized_N + 3.5 * normalized_T - 0.05
          a <- 1.3 * normalized_W + 0.5
          
        } else {

          v <- 1.3 * normalized_N + 2.7 * normalized_T - 0.05
          a <- 1.4 * normalized_W + 0.6
          
        }
      } else {
        # mismatch 条件
        v <- 1.1 * normalized_N + 1.7 * normalized_T - 0.05
        a <- 1.2 * normalized_W + 0.8
      }

      # 固定参数
      z <- 0.5
      t <- 0.5
      
      # 试次循环
      for (trial in 1:trials_per_condition) {
        # 优化4：参数有效性检查（不能为负，避免异常值导致模拟失败）
        if (v <= 0) v <- 0.1  # 确保 v 不为负数
        if (a <= 0) a <- 0.1  # 确保 a 不为负数

        # 生成单次试验数据
        # 优化5：错误捕获（避免单个试次模拟出错导致整个程序崩溃）
        sim_data <- tryCatch({
          rwiener(1, a, t, z, v)
        }, error = function(e) {
          return(data.frame(q = NA, resp = NA))
        })
        
        # 存储到list
        simulated_data[[idx]] <- data.frame(
          subj_idx = subj, 
          trial_idx = idx,
          rt = sim_data$q, 
          response = sim_data$resp, 
          v = v, a = a, t = t, z = z,
          N = N, T = T, W = W,
          NN = normalized_N, NT = normalized_T, NW = normalized_W,
          matchness = conditions$match[cond], 
          label = conditions$label[cond]
        )
        idx <- idx + 1
      }
    }
  }
  
  # 将list合并为dataframe
  simulated_data <- bind_rows(simulated_data)
  return(simulated_data)
}
```

```{r}
# 使用边际递减因子 (1 - 0.1 * normalized_N * normalized_W)，使得在 N 和 W 较高时增幅减小
generate_ddm_simulations_optimized <- function(n_subjects, n_trials_per_subject) {
  simulated_data <- data.frame()
  
  # 定义实验条件
  conditions <- expand.grid(match = c("match", "mismatch"), 
                            label = c("self", "friend", "stranger"))
  
  trials_per_condition <- n_trials_per_subject / nrow(conditions)
  
  for (subj in 1:n_subjects) {
    
    # 被试的个体参数（简化：直接写死取值范围，去掉了函数参数中的N_range/W_range）
    N <- sample(1:100, 1, replace = TRUE)  # 练习次数
    W <- sample(500:3000, 1, replace = TRUE)  # 响应窗口
    
    # 归一化（简化：直接代入最小值/最大值，去掉了变量存储的范围参数）
    normalized_N <- (N - 1) / (100 - 1)  # 将N归一化到[0, 1]
    normalized_W <- (W - 500) / (3000 - 500)  # 将W归一化到[0, 1]
    
    # 维护全局的 trial_idx
    trial_idx <- 1  # 初始化 trial_idx，从 1 开始
    
    for (cond in 1:nrow(conditions)) {
      # 核心优化1：所有条件的v都加“边际递减因子
      if (conditions$match[cond] == "match") {
        if (conditions$label[cond] == "self") {
          v <- (1.5 * normalized_N + 5.6 * normalized_W) * (1 - 0.1 * normalized_N * normalized_W) - 0.05
        } else if (conditions$label[cond] == "friend") {
          v <- (1.4 * normalized_N + 3.5 * normalized_W) * (1 - 0.1 * normalized_N * normalized_W) - 0.05
        } else {
          v <- (1.3 * normalized_N + 2.7 * normalized_W) * (1 - 0.1 * normalized_N * normalized_W) - 0.05
        }
      } else {
        v <- (1.1 * normalized_N + 1.7 * normalized_W) * (1 - 0.1 * normalized_N * normalized_W) - 0.05
      }
      # 核心优化2：使其随练习次数略微下降（练习越多，决策越不谨慎）
      # 例如：a = a_base - 0.005 * normalized_N
      a_base <- 1.2 * normalized_W + 0.8  # 决策阈值的基础值
      a <- a_base - 0.005 * normalized_N  # 随着练习次数增加而略微下降
      
      # 固定的非决策时间 (t) 和起始偏差 (z)
      z <- 0.5
      t <- 0.5
      
      for (trial in 1:trials_per_condition) {
        # 生成原始反应时间和反应
        sim_data <- rwiener(1, a, t, z, v)
        
        # 保存数据
        sim_data_df <- data.frame(subj_idx = subj, 
                                  trial_idx = trial_idx,  # 使用全局 trial_idx
                                  rt = sim_data$q, 
                                  response = sim_data$resp, 
                                  v = v, a = a, t = t, z = z,
                                  N = N, W = W,
                                  NN = normalized_N, NW = normalized_W,
                                  matchness = conditions$match[cond], 
                                  label = conditions$label[cond])
        simulated_data <- rbind(simulated_data, sim_data_df)
        
        # 更新 trial_idx，跨条件递增
        trial_idx <- trial_idx + 1
      }
    }
  }
  simulated_data
}
```

```{r}
# sigmoid
generate_ddm_simulations_optimized <- function(n_subjects, n_trials_per_subject,
                                               N_range = c(1, 100),
                                               T_range = c(50, 600),
                                               W_range = c(500, 3000)) {
  # 定义实验条件
  conditions <- expand.grid(match = c("match", "mismatch"), 
                            label = c("self", "friend", "stranger"))
  trials_per_condition <- n_trials_per_subject / nrow(conditions)
  
  # 创建空的list存储模拟数据
  simulated_data <- vector("list", n_subjects * n_trials_per_subject)
  idx <- 1  # 用于跟踪存储位置
  
  # 定义柔性趋势函数
  sigmoid <- function(x, midpoint, scale) {
    1 / (1 + exp(-scale * (x - midpoint)))
  }
  
  for (subj in 1:n_subjects) {
    # 随机抽取被试层级参数
    N <- sample(N_range[1]:N_range[2], 1)
    T <- sample(T_range[1]:T_range[2], 1)
    W <- sample(W_range[1]:W_range[2], 1)
    
    # 参数归一化
    normalized_N <- (N - N_range[1]) / (N_range[2] - N_range[1])
    normalized_T <- (T - T_range[1]) / (T_range[2] - T_range[1])
    normalized_W <- (W - W_range[1]) / (W_range[2] - W_range[1])
    
    # 条件循环
    for (cond in 1:nrow(conditions)) {
      # 初始化 v 和 a
      v <- 0
      a <- 0
      
      # 判断条件
      if (conditions$match[cond] == "match") {
        if (conditions$label[cond] == "self") {
          # v 的趋势：N > 20 和 W > 1800 时增长减缓
          v_trend <- 1.5 * sigmoid(normalized_N, midpoint = 0.2, scale = 5) + 
                     5.6 * sigmoid(normalized_W, midpoint = 0.6, scale = 2)
          v_noise <- rnorm(1, mean = 0, sd = 0.1)  # 添加随机扰动
          v <- v_trend + v_noise
          
          # a 的趋势：W 在 1100-1500 时最佳
          if (W < 1100) {
            a <- 1.2 * normalized_W + rnorm(1, mean = 0.1, sd = 0.05)  # 激进
          } else if (W > 1500) {
            a <- 1.2 * normalized_W - rnorm(1, mean = 0.2, sd = 0.05)  # 保守
          } else {
            a <- 1.5 + rnorm(1, mean = 0, sd = 0.05)  # 最佳
          }
        } else if (conditions$label[cond] == "friend") {
          # v 和 a 默认趋势
          v <- 1.4 * sigmoid(normalized_N, midpoint = 0.3, scale = 3) +
               3.5 * sigmoid(normalized_T, midpoint = 0.5, scale = 2) +
               rnorm(1, mean = 0, sd = 0.1)
          a <- 1.3 * normalized_W + rnorm(1, mean = 0, sd = 0.05)
        } else {
          # stranger 条件
          v <- 1.3 * normalized_N + 2.7 * normalized_T - 0.05 + rnorm(1, mean = 0, sd = 0.1)
          a <- 1.4 * normalized_W + 0.6 + rnorm(1, mean = 0, sd = 0.05)
        }
      } else {
        # mismatch 条件
        v <- 1.1 * normalized_N + 1.7 * normalized_T - 0.05 + rnorm(1, mean = 0, sd = 0.1)
        a <- 1.2 * normalized_W + 0.8 + rnorm(1, mean = 0, sd = 0.05)
      }
      
      # 固定参数
      z <- 0.5
      t <- 0.5
      
      # 试次循环
      for (trial in 1:trials_per_condition) {
        # 检查 v 和 a 的值范围（避免异常）
        v <- max(v, 0.1)  # 确保 v 不为负数
        a <- max(a, 0.1)  # 确保 a 不为负数
        
        # 生成单次试验数据
        sim_data <- tryCatch({
          rwiener(1, a, t, z, v)
        }, error = function(e) {
          return(data.frame(q = NA, resp = NA))
        })
        
        # 存储到list
        simulated_data[[idx]] <- data.frame(
          subj_idx = subj, 
          trial_idx = idx,
          rt = sim_data$q, 
          response = sim_data$resp, 
          v = v, a = a, t = t, z = z,
          N = N, T = T, W = W,
          NN = normalized_N, NT = normalized_T, NW = normalized_W,
          matchness = conditions$match[cond], 
          label = conditions$label[cond]
        )
        idx <- idx + 1
      }
    }
  }
  
  # 将list合并为dataframe
  simulated_data <- bind_rows(simulated_data)
  return(simulated_data)
}
```

```{r}
# 高斯分布
generate_ddm_simulations_optimized <- function(n_subjects, n_trials_per_subject,
                                              N_range = c(1, 100),
                                              T_range = c(50, 600),
                                              W_range = c(500, 3000)) {
  # 定义实验条件
  conditions <- expand.grid(match = c("match", "mismatch"), 
                            label = c("self", "friend", "stranger"))
  trials_per_condition <- n_trials_per_subject / nrow(conditions)
  
  # 创建空的list存储模拟数据
  simulated_data <- vector("list", n_subjects * n_trials_per_subject)
  idx <- 1  # 用于跟踪存储位置
  
  # 高斯函数
  gaussian <- function(x, center, sigma) {
    exp(- (x - center)^2 / (2 * sigma^2))
  }
  
  for (subj in 1:n_subjects) {
    # 随机抽取被试层级参数
    N <- sample(N_range[1]:N_range[2], 1)
    T <- sample(T_range[1]:T_range[2], 1)
    W <- sample(W_range[1]:W_range[2], 1)
    
    # 参数归一化
    normalized_N <- (N - N_range[1]) / (N_range[2] - N_range[1])
    normalized_W <- (W - W_range[1]) / (W_range[2] - W_range[1])
    
    # 条件循环
    for (cond in 1:nrow(conditions)) {
      # 初始化 v 和 a
      v <- 0
      a <- 0
      
      if (conditions$match[cond] == "match") {
        if (conditions$label[cond] == "self") {
          # Drift rate v: 中间值效应量最大
          v <- 1.5 * gaussian(N, center = 15, sigma = 15) * 
               gaussian(W, center = 1500, sigma = 300) + 
               rnorm(1, mean = 0, sd = 0.05)  # 添加噪声
          
          # Boundary separation a: W 在 1100-1500 时最大
          a <- 1.0 + 0.5 * gaussian(W, center = 2500, sigma = 200) + 
               rnorm(1, mean = 0, sd = 0.05)  # 添加噪声
        } else if (conditions$label[cond] == "friend") {
          # 默认逻辑
          v <- 1.4 * gaussian(N, center = 40, sigma = 20) +
               0.5 * gaussian(W, center = 1400, sigma = 300) +
               rnorm(1, mean = 0, sd = 0.05)
          a <- 1.2 + 0.3 * gaussian(W, center = 1400, sigma = 200) + 
               rnorm(1, mean = 0, sd = 0.05)
        } else {
          # stranger 条件
          v <- 1.3 * gaussian(N, center = 30, sigma = 25) +
               rnorm(1, mean = 0, sd = 0.05)
          a <- 1.4 + rnorm(1, mean = 0, sd = 0.05)
        }
      } else {
        # mismatch 条件
        v <- 1.2 * gaussian(N, center = 60, sigma = 20) + 
             rnorm(1, mean = 0, sd = 0.05)
        a <- 1.1 + 0.2 * gaussian(W, center = 1600, sigma = 300) + 
             rnorm(1, mean = 0, sd = 0.05)
      }
      
      # 固定参数
      z <- 0.5
      t <- 0.5
      
      # 试次循环
      for (trial in 1:trials_per_condition) {
        # 检查 v 和 a 的值范围（避免异常）
        v <- max(v, 0.1)  # 确保 v 不为负数
        a <- max(a, 0.1)  # 确保 a 不为负数
        
        # 生成单次试验数据
        sim_data <- tryCatch({
          rwiener(1, a, t, z, v)
        }, error = function(e) {
          return(data.frame(q = NA, resp = NA))
        })
        
        # 存储到list
        simulated_data[[idx]] <- data.frame(
          subj_idx = subj, 
          trial_idx = idx,
          rt = sim_data$q, 
          response = sim_data$resp, 
          v = v, a = a, t = t, z = z,
          N = N, T = T, W = W,
          NN = normalized_N, NT = T, NW = normalized_W,
          matchness = conditions$match[cond], 
          label = conditions$label[cond]
        )
        idx <- idx + 1
      }
    }
  }
  
  # 将list合并为dataframe
  simulated_data <- bind_rows(simulated_data)
  return(simulated_data)
}
```

```{r}
# 混合模型
generate_ddm_simulations_mixture <- function(n_subjects, n_trials_per_subject,
                                             N_range = c(1, 100),
                                             T_range = c(50, 600),
                                             W_range = c(500, 3000)) {
  # 定义实验条件
  conditions <- expand.grid(match = c("match", "mismatch"), 
                            label = c("self", "friend", "stranger"))
  trials_per_condition <- n_trials_per_subject / nrow(conditions)
  
  # 创建空的list存储模拟数据
  simulated_data <- vector("list", n_subjects * n_trials_per_subject)
  idx <- 1  # 用于跟踪存储位置
  
  # 定义混合权重函数
  weight <- function(x, center, sigma) {
    exp(- (x - center)^2 / (2 * sigma^2))  # 高斯分布权重
  }
  
  for (subj in 1:n_subjects) {
    # 随机抽取被试层级参数
    N <- sample(N_range[1]:N_range[2], 1)
    T <- sample(T_range[1]:T_range[2], 1)
    W <- sample(W_range[1]:W_range[2], 1)
    
    # 参数归一化
    normalized_N <- (N - N_range[1]) / (N_range[2] - N_range[1])
    normalized_W <- (W - W_range[1]) / (W_range[2] - W_range[1])
    
    # 条件循环
    for (cond in 1:nrow(conditions)) {
      # 初始化 v 和 a
      v <- 0
      a <- 0
      
      if (conditions$match[cond] == "match") {
        if (conditions$label[cond] == "self") {
          # Linear and nonlinear submodels for v
          v_linear <- 1.5 * normalized_N + 5.6 * normalized_W  # 线性部分
          v_nonlinear <- 2.0 * exp(- ((N - 50)^2) / (2 * 15^2)) * 
                         exp(- ((W - 1500)^2) / (2 * 300^2))  # 高斯峰值部分
          
          # Weights for v
          w1 <- weight(N, center = 50, sigma = 15)
          w2 <- weight(W, center = 1500, sigma = 300)
          
          # Mixture model for v
          v <- w1 * v_linear + (1 - w1) * v_nonlinear + rnorm(1, mean = 0, sd = 0.05)
          
          # Linear and nonlinear submodels for a
          a_linear <- 1.2 * normalized_W  # 线性部分
          a_nonlinear <- 1.0 + 0.5 * exp(- ((W - 1500)^2) / (2 * 200^2))  # 中间值峰值部分
          
          # Weights for a
          w1_a <- weight(W, center = 1500, sigma = 200)
          
          # Mixture model for a
          a <- w1_a * a_linear + (1 - w1_a) * a_nonlinear + rnorm(1, mean = 0, sd = 0.05)
        } else if (conditions$label[cond] == "friend") {
          # 默认逻辑
          v <- 1.4 * normalized_N + 3.5 * normalized_W +
               rnorm(1, mean = 0, sd = 0.05)
          a <- 1.3 * normalized_W + rnorm(1, mean = 0, sd = 0.05)
        } else {
          # stranger 条件
          v <- 1.3 * normalized_N + 2.7 * normalized_W - 0.05 + 
               rnorm(1, mean = 0, sd = 0.05)
          a <- 1.4 * normalized_W + 0.6 + rnorm(1, mean = 0, sd = 0.05)
        }
      } else {
        # mismatch 条件
        v <- 1.1 * normalized_N + 1.7 * normalized_W - 0.05 + 
             rnorm(1, mean = 0, sd = 0.05)
        a <- 1.2 * normalized_W + 0.8 + rnorm(1, mean = 0, sd = 0.05)
      }
      
      # 固定参数
      z <- 0.5
      t <- 0.5
      
      # 试次循环
      for (trial in 1:trials_per_condition) {
        # 检查 v 和 a 的值范围（避免异常）
        v <- max(v, 0.1)  # 确保 v 不为负数
        a <- max(a, 0.1)  # 确保 a 不为负数
        
        # 生成单次试验数据
        sim_data <- tryCatch({
          rwiener(1, a, t, z, v)
        }, error = function(e) {
          return(data.frame(q = NA, resp = NA))
        })
        
        # 存储到list
        simulated_data[[idx]] <- data.frame(
          subj_idx = subj, 
          trial_idx = idx,
          rt = sim_data$q, 
          response = sim_data$resp, 
          v = v, a = a, t = t, z = z,
          N = N, T = T, W = W,
          NN = normalized_N, NT = T, NW = normalized_W,
          matchness = conditions$match[cond], 
          label = conditions$label[cond]
        )
        idx <- idx + 1
      }
    }
  }
  
  # 将list合并为dataframe
  simulated_data <- bind_rows(simulated_data)
  return(simulated_data)
}
```

```{r}
generate_simple_ddm_simulations <- function(n_subjects, n_trials_per_subject,
                                            N_range = c(1, 100),
                                            W_range = c(500, 3000)) {
  # 定义实验条件
  conditions <- expand.grid(match = c("match", "mismatch"), 
                            label = c("self", "friend", "stranger"))
  trials_per_condition <- n_trials_per_subject / nrow(conditions)
  
  simulated_data <- vector("list", n_subjects * n_trials_per_subject)
  idx <- 1
  
  for (subj in 1:n_subjects) {
    # 随机生成 N 和 W
    N <- sample(N_range[1]:N_range[2], 1)
    W <- sample(W_range[1]:W_range[2], 1)
    
    # 参数归一化
    normalized_N <- (N - N_range[1]) / (N_range[2] - N_range[1])
    normalized_W <- (W - W_range[1]) / (W_range[2] - W_range[1])
    
    for (cond in 1:nrow(conditions)) {
      # 定义简单的趋势函数
      if (conditions$match[cond] == "match" && conditions$label[cond] == "self") {
        # v 在中间值附近达到最大
        v <- 2.0 * exp(-((N - 12)^2) / (2 * 15^2)) * exp(-((W - 1500)^2) / (2 * 300^2)) +
             rnorm(1, mean = 0, sd = 0.1)  # 添加随机噪声
        
        # a 在 W = 1100-1500 达到最佳
        if (W < 1100) {
          a <- 1.6 + rnorm(1, mean = 0.1, sd = 0.05)  # 激进
        } else if (W > 1500) {
          a <- 1.0 + rnorm(1, mean = -0.1, sd = 0.05)  # 保守
        } else {
          a <- 1.2 + rnorm(1, mean = 0, sd = 0.05)  # 最佳水平
        }
      } else {
        # 其他条件默认趋势
        v <- 1.5 * normalized_N + rnorm(1, mean = 0, sd = 0.1)
        a <- 1.2 * normalized_W + rnorm(1, mean = 0, sd = 0.05)
      }
      
      # 固定参数
      z <- 0.5
      t <- 0.5
      
      for (trial in 1:trials_per_condition) {
        v <- max(v, 0.1)
        a <- max(a, 0.1)
        
        sim_data <- tryCatch({
          rwiener(1, a, t, z, v)
        }, error = function(e) {
          return(data.frame(q = NA, resp = NA))
        })
        
        simulated_data[[idx]] <- data.frame(
          subj_idx = subj, trial_idx = idx, rt = sim_data$q, response = sim_data$resp,
          v = v, a = a, t = t, z = z, N = N, W = W,
          matchness = conditions$match[cond], label = conditions$label[cond]
        )
        idx <- idx + 1
      }
    }
  }
  
  simulated_data <- bind_rows(simulated_data)
  return(simulated_data)
}
```

```{r}
# 假设有100个被试，每个被试完成360个试次，每个条件下各60个试次
set.seed(032)
n_subjects <- 100
n_trials_per_subject <- 360

simulated_ddm_data_optimized <- generate_ddm_simulations_optimized(n_subjects, n_trials_per_subject)
```

```{r}
simulated_ddm_data_optimized
```

# Raw Data Visualization
## original
```{r}
summary(simulated_ddm_data$rt*1000)
summary(simulated_ddm_data$v)
summary(simulated_ddm_data$a)
```

```{r}
# 优化前
# 反应时间（rt）的分布
library(ggplot2)
ggplot(simulated_ddm_data, aes(x = rt * 1000)) +  # 将 rt 转换为毫秒
  geom_histogram(binwidth = 100, fill = "#547689", color = "black") +  # binwidth 可以根据数据调整
  labs(title = "Reaction Time (RT) Distribution", x = "Reaction Time (ms)", y = "Frequency") +
  scale_x_continuous(limits = c(0, 2000)) +  # 设置 x 轴范围为 0 到 2000
  papaja::theme_apa()

# 漂移速率（v）的分布
ggplot(simulated_ddm_data, aes(x = v)) +
  geom_histogram(binwidth = 0.1, fill = "#cc5d20", color = "black") +
  labs(title = "Drift Rate (v) Distribution", x = "Drift Rate", y = "Frequency") +
  papaja::theme_apa()

# 阈值（a）的分布
ggplot(simulated_ddm_data, aes(x = a)) +
  geom_histogram(binwidth = 0.1, fill = "#698e6a", color = "black") +
  labs(title = "Threshold (a) Distribution", x = "Threshold", y = "Frequency") +
  papaja::theme_apa()
```

```{r}
# 不同条件下的反应时间比较
ggplot(simulated_ddm_data, aes(x = matchness, y = rt, fill = label)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Matchness and Label", x = "Matchness", y = "Reaction Time")  +
  papaja::theme_apa()

# 不同条件下的漂移速率比较
ggplot(simulated_ddm_data, aes(x = matchness, y = v, fill = label)) +
  geom_boxplot() +
  labs(title = "Drift Rate by Matchness and Label", x = "Matchness", y = "Drift Rate")  +
  papaja::theme_apa()

# 不同条件下的阈值比较
ggplot(simulated_ddm_data, aes(x = matchness, y = a, fill = label)) +
  geom_boxplot() +
  labs(title = "Threshold by Matchness and Label", x = "Matchness", y = "Threshold") +
  papaja::theme_apa()
```

## optimal
```{r}
summary(simulated_ddm_data_optimized$rt*1000)
summary(simulated_ddm_data_optimized$v)
summary(simulated_ddm_data_optimized$a)
```

```{r}
# 优化后
# 反应时间（rt）的分布
ggplot(simulated_ddm_data_optimized, aes(x = rt * 1000)) +  # 将 rt 转换为毫秒
  geom_histogram(binwidth = 100, fill = "#547689", color = "black") +  # binwidth 可以根据数据调整
  labs(title = "Reaction Time (RT) Distribution", x = "Reaction Time (ms)", y = "Frequency") +
  scale_x_continuous(limits = c(0, 2000)) +  # 设置 x 轴范围为 0 到 2000
  papaja::theme_apa()

# 漂移速率（v）的分布
ggplot(simulated_ddm_data_optimized, aes(x = v)) +
  geom_histogram(binwidth = 0.1, fill = "#cc5d20", color = "black") +
  labs(title = "Drift Rate (v) Distribution", x = "Drift Rate", y = "Frequency") +
  papaja::theme_apa()

# 阈值（a）的分布
ggplot(simulated_ddm_data_optimized, aes(x = a)) +
  geom_histogram(binwidth = 0.1, fill = "#698e6a", color = "black") +
  labs(title = "Threshold (a) Distribution", x = "Threshold", y = "Frequency") +
  papaja::theme_apa()
```

```{r}
# 不同条件下的反应时间比较
ggplot(simulated_ddm_data_optimized, aes(x = matchness, y = rt, fill = label)) +
  geom_boxplot() +
  labs(title = "Reaction Time by Matchness and Label", x = "Matchness", y = "Reaction Time")  +
  papaja::theme_apa()

# 不同条件下的漂移速率比较
ggplot(simulated_ddm_data_optimized, aes(x = matchness, y = v, fill = label)) +
  geom_boxplot() +
  labs(title = "Drift Rate by Matchness and Label", x = "Matchness", y = "Drift Rate")  +
  papaja::theme_apa()

# 不同条件下的阈值比较
ggplot(simulated_ddm_data_optimized, aes(x = matchness, y = a, fill = label)) +
  geom_boxplot() +
  labs(title = "Threshold by Matchness and Label", x = "Matchness", y = "Threshold") +
  papaja::theme_apa()
```

# Data Preprocessing
## original
```{r}
# data preprocessing
# 在match条件下upper是match，在mismatch条件下upper是mismatch
df1 <- simulated_ddm_data %>%
  mutate(
    response = case_when(
      matchness == "match" & response == "upper" ~ "match",
      matchness == "match" & response == "lower" ~ "mismatch",
      matchness == "mismatch" & response == "upper" ~ "mismatch",
      matchness == "mismatch" & response == "lower" ~ "match"
    ),
    rt = rt * 1000,
    acc = ifelse(matchness == response, 1, 0)
  )
```

```{r}
# data preprocessing-Cohen's d
# 逐个被试计算效应量，保持了被试的个体差异
# 这里把匹配条件下non-self与self的均值差异除以合并标准差作为cohen‘s d，先暂时用stranger作为non-self了

# 定义计算 Cohen's d 的函数
calculate_cohen_d <- function(data) {
  # 提取自我条件和非自我条件的反应时间
  self_condition <- data$rt[data$label == "self"]
  non_self_condition <- data$rt[data$label == "stranger"]
  
  # 计算均值和标准差
  mean_self <- mean(self_condition)
  mean_non_self <- mean(non_self_condition)
  sd_self <- sd(self_condition)
  sd_non_self <- sd(non_self_condition)
  
  # 样本量
  n_self <- length(self_condition)
  n_non_self <- length(non_self_condition)
  
  # 合并标准差
  pooled_sd <- sqrt(((n_self - 1) * sd_self^2 + (n_non_self - 1) * sd_non_self^2) / (n_self + n_non_self - 2))
  
  # 计算 Cohen's d
  cohen_d <- (mean_non_self - mean_self) / pooled_sd
  return(cohen_d)
}

# 创建一个新的列来存储 Cohen's d
df1$cohen_d <- NA

# 获取唯一的被试 ID
unique_subjects <- unique(df1$subj_idx)

# 使用 for 循环逐个计算每个被试的 Cohen's d
for (subj in unique_subjects) {
  # 筛选出当前被试的所有 trial 数据
  subj_data <- df1[df1$subj_idx == subj, ]
  
  # 计算当前被试的 Cohen's d
  cohen_d_value <- calculate_cohen_d(subj_data)
  
  # 将计算好的 Cohen's d 填入 df 中对应的行
  df1$cohen_d[df1$subj_idx == subj] <- cohen_d_value
}
```

```{r}
# data preprocessing-mean
mean1 <- df1 %>%
  group_by(subj_idx, matchness, label) %>%
  summarise(
    RT = mean(rt), RT_sd = sd(rt),
    ACC = mean(acc == 1), ACC_sd = sqrt(mean(acc == 1) * (1 - mean(acc == 1)) / n()), # 这里应该用公式还是直接sd？
    N = mean(N), T = mean(T), W = mean(W),
    NN = mean(NN), NT = mean(NT), NW = mean(NW),
    a = mean(a), t = mean(t), z = mean(z), v = mean(v),cohen_d = mean(cohen_d),
    .groups = "drop"
  )

# 被试每个条件下的v,a是不同的，不能平均
subj.mean1 <- df1  %>%
  group_by(subj_idx) %>%
  summarise(
    cohen_d = mean(cohen_d),
    N = mean(N), T = mean(T), W = mean(W),
    NN = mean(NN), NT = mean(NT), NW = mean(NW),
    v = mean(v),  # 新增：计算每个被试的平均漂移率v
    a = mean(a),  # 可选：若后续需要，可同时添加a的被试均值
    .groups = "drop"
    )

grand.mean1 <- mean1 %>%
  group_by(matchness, label) %>%
  summarise(
    RT = mean(RT), ACC = mean(ACC),
    N = mean(N), T = mean(T), W = mean(W),
    NN = mean(NN), NT = mean(NT), NW = mean(NW),
    .groups = "drop"
  )
```

```{r}
summary(mean1$v)
summary(subj.mean1$v)
```


```{r}
# 参数与正则化维度数据宽转长
ddm_long1 <- mean1 %>% gather(key = "Paras", value = "Value", v, a, t, z)
mean_long1 <- mean1 %>% gather(key = "Dims", value = "Value", NN, NT, NW)
```

## optimal
```{r}
#优化后
df2 <- simulated_ddm_data_optimized %>%
  mutate(
    response = case_when(
      matchness == "match" & response == "upper" ~ "match",
      matchness == "match" & response == "lower" ~ "mismatch",
      matchness == "mismatch" & response == "upper" ~ "mismatch",
      matchness == "mismatch" & response == "lower" ~ "match"
    ),
    rt = rt * 1000,
    acc = ifelse(matchness == response, 1, 0)
  )
```

```{r}
# data preprocessing-Cohen's d
# 创建一个新的列来存储 Cohen's d
df2$cohen_d <- NA

# 获取唯一的被试 ID
unique_subjects <- unique(df2$subj_idx)

# 使用 for 循环逐个计算每个被试的 Cohen's d
for (subj in unique_subjects) {
  # 筛选出当前被试的所有 trial 数据
  subj_data <- df2[df2$subj_idx == subj, ]
  
  # 计算当前被试的 Cohen's d
  cohen_d_value <- calculate_cohen_d(subj_data)
  
  # 将计算好的 Cohen's d 填入 df 中对应的行
  df2$cohen_d[df2$subj_idx == subj] <- cohen_d_value
}
```

```{r}
mean2 <- df2  %>%
  group_by(subj_idx, matchness, label) %>%
  summarise(
    RT = mean(rt), RT_sd = sd(rt),
     ACC = mean(acc == 1), ACC_sd = sqrt(mean(acc == 1) * (1 - mean(acc == 1)) / n()),
    N = mean(N),T = mean(T), W = mean(W),
    NN = mean(NN), NT = mean(NT),NW = mean(NW),
    a = mean(a), t = mean(t), z = mean(z), v = mean(v),cohen_d = mean(cohen_d),
    .groups = "drop"
    )

subj.mean2 <- df2  %>%
  group_by(subj_idx) %>%
  summarise(
    cohen_d = mean(cohen_d),
    N = mean(N), T = mean(T), W = mean(W),
    NN = mean(NN), NT = mean(NT), NW = mean(NW),
    a = mean(a), t = mean(t), z = mean(z), v = mean(v),
    .groups = "drop"
    )

grand.mean2 <- mean2 %>%
  group_by(matchness, label) %>%
  summarise(
    RT = mean(RT), ACC = mean(ACC),
    N = mean(N), W = mean(W),
    NN = mean(NN), NW = mean(NW),
    a = mean(a), t = mean(t), z = mean(z), v = mean(v),
    .groups = "drop"
  )
```

```{r}
# 参数与正则化维度数据宽转长
ddm_long2 <- mean2 %>% gather(key = "Paras", value = "Value", v, a, t, z)
mean_long2 <- mean2 %>% gather(key = "Dims", value = "Value", NN, NW)
```

# Marginal Distribution Plot
## original
```{r}
# 创建基础散点图（无边际分布）
plot_original <- ggplot(subj.mean1, aes(x = N, y = W, color = cohen_d)) +  # 使用 cohen_d_rt 作为颜色映射
  geom_point(alpha = 0.6, size = 3) + 
  scale_color_gradient(low = "lightblue", high = "darkblue") +  # 使用浅蓝色到深蓝色的渐变
  theme_minimal() +
  labs(
    x = "Practice Number", 
    y = "Response Window", 
    color = "Cohen d"  # 修改图例标题
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    legend.position = "none"  # 先隐藏图例
  )

# 添加边际分布
plot_original_marginal <- ggExtra::ggMarginal(
  plot_original, 
  type = "histogram",  # 边际分布类型
  margins = "both",    # 同时显示上下和左右分布
  size = 5,            # 边际分布区域大小
  fill = "gray",       # 直方图填充颜色
  color = "black",     # 边框颜色
  alpha = 0.5          # 透明度
)

# 提取图例（单独创建图例）
plot_original_legend <- ggplot(subj.mean1, aes(x = N, y = W, color = cohen_d)) +  # 使用 cohen_d_rt 作为颜色映射
  geom_point(alpha = 0.6, size = 3) + 
  scale_color_gradient(low = "lightblue", high = "darkblue") +  # 使用浅蓝色到深蓝色的渐变
  labs(
    color = "Cohen's d"  # 修改图例的标题为 "Cohen's d"
  ) +
  theme_void() +  # 移除背景
  theme(
    legend.position = "right"  # 图例位置
  )

# 提取图例对象
plot_original_legend <- cowplot::get_legend(plot_original_legend)

# 组合主图和图例
plot_original_final <- cowplot::plot_grid(
  plot_original_marginal, plot_original_legend, 
  ncol = 2, 
  rel_widths = c(4, 1)  # 主图占 4/5 宽度，图例占 1/5 宽度
)

plot_original_final
```

## optimal
```{r}
# 创建基础散点图（无边际分布）
plot_optimal <- ggplot(subj.mean2, aes(x = N, y = W, color = cohen_d)) +  # 使用 cohen_d_rt 作为颜色映射
  geom_point(alpha = 0.6, size = 3) + 
  scale_color_gradient(low = "lightblue", high = "darkblue") +  # 使用浅蓝色到深蓝色的渐变
  theme_minimal() +
  labs(
    x = "Practice Number", 
    y = "Response Window", 
    color = "Cohen d"  # 修改图例标题
  ) +
  theme(
    plot.title = element_text(hjust = 0.5, size = 14),
    legend.position = "none"  # 先隐藏图例
  )

# 添加边际分布
plot_optimal_marginal <- ggExtra::ggMarginal(
  plot_optimal, 
  type = "histogram",  # 边际分布类型
  margins = "both",    # 同时显示上下和左右分布
  size = 5,            # 边际分布区域大小
  fill = "gray",       # 直方图填充颜色
  color = "black",     # 边框颜色
  alpha = 0.5          # 透明度
)

# 提取图例（单独创建图例）
plot_optimal_legend <- ggplot(subj.mean2, aes(x = N, y = W, color = cohen_d)) +  # 使用 cohen_d_rt 作为颜色映射
  geom_point(alpha = 0.6, size = 3) + 
  scale_color_gradient(low = "lightblue", high = "darkblue") +  # 使用浅蓝色到深蓝色的渐变
  labs(
    color = "Cohen's d"  # 修改图例的标题为 "Cohen's d"
  ) +
  theme_void() +  # 移除背景
  theme(
    legend.position = "right"  # 图例位置
  )

# 提取图例对象
plot_optimal_legend <- cowplot::get_legend(plot_optimal_legend)

# 组合主图和图例
plot_optimal_final <- cowplot::plot_grid(
  plot_optimal_marginal, plot_optimal_legend, 
  ncol = 2, 
  rel_widths = c(4, 1)  # 主图占 4/5 宽度，图例占 1/5 宽度
)

plot_optimal_final
```

# Contour Plot
```{r}
# 定义颜色映射函数
color_palette <- colorRampPalette(c("white", "lightblue", "red"))
```

## original
```{r}
try1 <- mean1 %>% filter(matchness  == "match" & label == "self")
```

```{r}
# N & w
library(plotly)
library(grDevices)  # 提供 colorRampPalette，通常默认加载

# 生成包含 100 种颜色的渐变色板（例如从蓝色到红色）
my_palette <- colorRampPalette(c("blue", "red"))(100)
plot_ly(try1, x = ~N, y = ~W, z = ~RT, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "RT")) %>%
  layout(title = "Contour Plot",
         xaxis = list(title = "N"),
         yaxis = list(title = "W"))

plot_ly(try1, x = ~W, y = ~N, z = ~RT, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "RT")) %>%
  layout(title = "Contour Plot",
         xaxis = list(title = "W"),
         yaxis = list(title = "N"))
```

```{r}
# N & w
plot_ly(subj.mean1, x = ~N, y = ~W, z = ~cohen_d, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Contour Plot of Cohen's d",
         xaxis = list(title = "N"),
         yaxis = list(title = "W"))

plot_ly(subj.mean1, x = ~W, y = ~N, z = ~cohen_d, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Contour Plot of Cohen's d",
         xaxis = list(title = "W"),
         yaxis = list(title = "N"))
```

```{r}
# 直接用原始数据绘制热图
plot_ly(subj.mean1, x = ~N, y = ~W, z = ~cohen_d, type = 'heatmap',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Heatmap of Cohen's d",
         xaxis = list(title = "Practice Number"),
         yaxis = list(title = "Response Window"))
```

```{r}
# T & w
plot_ly(subj.mean1, x = ~T, y = ~W, z = ~cohen_d, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Contour Plot of Cohen's d",
         xaxis = list(title = "T"),
         yaxis = list(title = "W"))

plot_ly(subj.mean1, x = ~W, y = ~T, z = ~cohen_d, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Contour Plot of Cohen's d",
         xaxis = list(title = "W"),
         yaxis = list(title = "T"))
```

```{r}
# N & T
plot_ly(subj.mean1, x = ~N, y = ~T, z = ~cohen_d, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Contour Plot of Cohen's d",
         xaxis = list(title = "N"),
         yaxis = list(title = "T"))

plot_ly(subj.mean1, x = ~T, y = ~N, z = ~cohen_d, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Contour Plot of Cohen's d",
         xaxis = list(title = "T"),
         yaxis = list(title = "N"))
```

## optimal
```{r}
try2 <- mean2 %>% filter(matchness  == "match" & label == "self")
```

```{r}
# N & w
plot_ly(try2, x = ~N, y = ~W, z = ~RT, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "RT")) %>%
  layout(title = "Contour Plot",
         xaxis = list(title = "N"),
         yaxis = list(title = "W"))

plot_ly(try2, x = ~W, y = ~N, z = ~RT, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "RT")) %>%
  layout(title = "Contour Plot",
         xaxis = list(title = "W"),
         yaxis = list(title = "N"))
```

```{r}
# N & w
plot_ly(subj.mean2, x = ~N, y = ~W, z = ~cohen_d, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Contour Plot of Cohen's d",
         xaxis = list(title = "N"),
         yaxis = list(title = "W"))

plot_ly(subj.mean2, x = ~W, y = ~N, z = ~cohen_d, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Contour Plot of Cohen's d",
         xaxis = list(title = "W"),
         yaxis = list(title = "N"))
```

```{r}
# 直接用原始数据绘制热图
plot_ly(subj.mean2, x = ~N, y = ~W, z = ~cohen_d, type = 'heatmap',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Heatmap of Cohen's d",
         xaxis = list(title = "Practice Number"),
         yaxis = list(title = "Response Window"))
```

```{r}
# T & w
plot_ly(subj.mean2, x = ~T, y = ~W, z = ~cohen_d, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Contour Plot of Cohen's d",
         xaxis = list(title = "T"),
         yaxis = list(title = "W"))

plot_ly(subj.mean2, x = ~W, y = ~T, z = ~cohen_d, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Contour Plot of Cohen's d",
         xaxis = list(title = "W"),
         yaxis = list(title = "T"))
```

```{r}
# N & T
plot_ly(subj.mean2, x = ~N, y = ~T, z = ~cohen_d, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Contour Plot of Cohen's d",
         xaxis = list(title = "N"),
         yaxis = list(title = "T"))

plot_ly(subj.mean2, x = ~T, y = ~N, z = ~cohen_d, type = 'contour',
        colors = color_palette(100), colorbar = list(title = "Cohen's d")) %>%
  layout(title = "Contour Plot of Cohen's d",
         xaxis = list(title = "T"),
         yaxis = list(title = "N"))
```

# Paras and DV
## original
```{r}
ddm_long_oringal <- ddm_long1 %>% filter(Paras == "v" | Paras == "a" )

# plot the relationship between Paras and RT
ggplot(ddm_long_oringal, aes(x = Value, y = RT, color = factor(Paras))) +
  geom_smooth(alpha = 0.4) +
  geom_point(alpha = 0.2) +
  labs(x = "Value", y = "RT", title = "Relationship between Parameters and RT") +
  scale_color_manual(
    name = "Paras",
    labels = c("a", "v"),
    values = c("a" = "#b26d5d", "v" = "#6b798e")  
  ) +
  papaja::theme_apa()
```

```{r}
summary(try1$v)

ggplot(try1, aes(x = v, y = RT)) +
  geom_smooth(alpha = 0.4) +
  geom_point(alpha = 0.2, color = "blue") +
  scale_x_continuous(breaks = seq(0, max(try1$v), by = 0.5)) +
  papaja::theme_apa()
```

```{r}
summary(subj.mean1$v)

ggplot(subj.mean1, aes(x = v, y = cohen_d)) +
  geom_smooth(alpha = 0.4) +
  geom_point(alpha = 0.2, color = "blue") +
  scale_x_continuous(breaks = seq(0, max(subj.mean1$v), by = 0.5)) +
  papaja::theme_apa()
```


## optimal
```{r}
# plot the relationship between Paras and RT
ggplot(ddm_long2, aes(x = RT, y = Value, color = factor(Paras))) +
  geom_smooth(alpha = 0.4) +
  geom_point(alpha = 0.2) +
  labs(x = "RT", y = "Value", title = "Relationship between Parameters and RT") +
    scale_color_manual(
    name = "Paras",
    labels = c("a", "t", "v", "z"),
    values = c("a" = "#b26d5d", "t" = "#7e527f", "v" = "#6b798e", "z" = "#db9b34")  
  ) +
  papaja::theme_apa()
```

# t test
```{r}
mean3 <- df1  %>%
  group_by(subj_idx) %>%
  summarise(
    cohen_d = mean(cohen_d),
    N = mean(N), T = mean(T), W = mean(W),
    NN = mean(NN), NT = mean(NT), NW = mean(NW),
    a = mean(a), t = mean(t), z = mean(z), v = mean(v),
    .groups = "drop"
    )

mean4 <- df2  %>%
  group_by(subj_idx) %>%
  summarise(
    cohen_d = mean(cohen_d),
    N = mean(N), W = mean(W),
    NN = mean(NN), NW = mean(NW),
    a = mean(a), t = mean(t), z = mean(z), v = mean(v),
    .groups = "drop"
    )
```

```{r}
# 计算独立样本 t 检验
t_test_result <- t.test(mean3$cohen_d, mean4$cohen_d, var.equal = TRUE)  # 若方差不齐则设置 var.equal = FALSE
print(t_test_result)
```


# ANOVA
## Cohen's d
```{r}
# 优化前
anova_d1 <- bruceR::MANOVA(
  data = mean1,
  dv = "cohen_d",
  within = c("matchness", "label"),
  subID = "subj_idx")

# 优化后
anova_d2 <- bruceR::MANOVA(
  data = mean2,
  dv = "cohen_d",
  within = c("matchness", "label"),
  subID = "subj_idx")
```

## RT
```{r}
# 优化前
anova_rt1 <- bruceR::MANOVA(
  data = mean1,
  dv = "RT",
  within = c("matchness", "label"),
  subID = "subj_idx",
  sph.correction="GG")

# 优化后
anova_rt2 <- bruceR::MANOVA(
  data = mean2,
  dv = "RT",
  within = c("matchness", "label"),
  subID = "subj_idx",
  sph.correction="GG")
```

```{r}
performance::compare_performance(anova_rt1, anova_rt2, rank = TRUE, verbose = FALSE)
```

## ACC
```{r}
# 优化前
anova_acc1 <- bruceR::MANOVA(
  data = mean1,
  dv = "ACC",
  within = c("matchness", "label"),
  subID = "subj_idx")

# 优化后
anova_acc2 <- bruceR::MANOVA(
  data = mean2,
  dv = "ACC",
  within = c("matchness", "label"),
  subID = "subj_idx")
```

```{r}
performance::compare_performance(anova_acc1, anova_acc2, rank = TRUE, verbose = FALSE)
```

# LMM
## RT
```{r}
# 优化前
model1 <- lme4::lmer(data = mean1,
                     RT ~ matchness * label + (1|subj_idx))

summary(model1)

# 优化后
model2 <- lme4::lmer(data = mean2,
                     RT ~ matchness * label + (1|subj_idx))

summary(model2)
```

```{r}
performance::compare_performance(model1, model2, rank = TRUE, verbose = FALSE)
```

## ACC
```{r}
# 优化前
model3 <- lme4::lmer(data = mean1,
                     ACC ~ matchness * label + (1|subj_idx))

summary(model3)

# 优化后
model4 <- lme4::lmer(data = mean2,
                     ACC ~ matchness * label + (1|subj_idx))

summary(model4)
```

```{r}
performance::compare_performance(model3, model4, rank = TRUE, verbose = FALSE)
```

# Conds and DV
## original
```{r}
mean.plot1 <- mean1 %>%
  mutate(conds = case_when(
    matchness == "match" & label == "self" ~ "0.8",
    matchness == "match" & label == "friend" ~ "1.0",
    matchness == "match" & label == "stranger" ~ "1.2",
    matchness == "mismatch" & label == "self" ~ "1.8",
    matchness == "mismatch" & label == "friend" ~ "2.0",
    matchness == "mismatch" & label == "stranger" ~ "2.2"
  )) %>%
  mutate(conds = as.numeric(conds))
```

```{r}
# plot Conds and RT
p1 <- ggplot(grand.mean1, 
       aes(x = factor(matchness), y = RT, color = factor(label), group = factor(label))) +
  geom_line(position = position_dodge(0.6)) +
  geom_point(size = 3, position = position_dodge(0.6)) +
  labs(x = "match", y = "RT") +
  geom_point(data = mean.plot1,
             aes(x = conds, y = RT, group = factor(subj_idx)),
             position = position_dodge(0.06),
             alpha = 0.3) +
  geom_line(data = mean.plot1,
            aes(x = conds, y = RT, group = factor(subj_idx)),
            position = position_dodge(0.06),
            linetype = 1,
            size = 0.8,
            color = "#000000",
            alpha = 0.05) +
  scale_color_manual(
    name = "label",
    labels = c("self", "friend", "stranger"),
    values = c("self" = "#b26d5d", "friend" = "#6b798e", "stranger" = "#7e527f")  
  ) +
  papaja::theme_apa()

p1
```

```{r}
# plot Conds and ACC
p2 <- ggplot(grand.mean1, 
       aes(x = factor(matchness), y = ACC, color = factor(label), group = factor(label))) +
  geom_line(position = position_dodge(0.6)) +
  geom_point(size = 3, position = position_dodge(0.6)) +
  labs(x = "match", y = "ACC") +
  geom_point(data = mean.plot1,
             aes(x = conds, y = ACC, group = factor(subj_idx)),
             position = position_dodge(0.06),
             alpha = 0.3) +
  geom_line(data = mean.plot1,
            aes(x = conds, y = ACC, group = factor(subj_idx)),
            position = position_dodge(0.06),
            linetype = 1,
            size = 0.8,
            color = "#000000",
            alpha = 0.05) +
  scale_color_manual(
    name = "label",
    labels = c("self", "friend", "stranger"),
    values = c("self" = "#b26d5d", "friend" = "#6b798e", "stranger" = "#7e527f")  
  ) +
  papaja::theme_apa()

p2
```

```{r}
p1 + p2 + 
  plot_layout(guides = 'collect')
```

## optimal
```{r}
mean.plot2 <- mean2 %>%
  mutate(conds = case_when(
    matchness == "match" & label == "self" ~ "0.8",
    matchness == "match" & label == "friend" ~ "1.0",
    matchness == "match" & label == "stranger" ~ "1.2",
    matchness == "mismatch" & label == "self" ~ "1.8",
    matchness == "mismatch" & label == "friend" ~ "2.0",
    matchness == "mismatch" & label == "stranger" ~ "2.2"
  )) %>%
  mutate(conds = as.numeric(conds))
```

```{r}
# plot Conds and RT
p3 <- ggplot(grand.mean2, 
       aes(x = factor(matchness), y = RT, color = factor(label), group = factor(label))) +
  geom_line(position = position_dodge(0.6)) +
  geom_point(size = 3, position = position_dodge(0.6)) +
  labs(x = "match", y = "RT") +
  geom_point(data = mean.plot2,
             aes(x = conds, y = RT, group = factor(subj_idx)),
             position = position_dodge(0.06),
             alpha = 0.3) +
  geom_line(data = mean.plot2,
            aes(x = conds, y = RT, group = factor(subj_idx)),
            position = position_dodge(0.06),
            linetype = 1,
            size = 0.8,
            color = "#000000",
            alpha = 0.05) +
  scale_color_manual(
    name = "label",
    labels = c("self", "friend", "stranger"),
    values = c("self" = "#b26d5d", "friend" = "#6b798e", "stranger" = "#7e527f")  
  ) +
  papaja::theme_apa()

p3
```

```{r}
# plot Conds and ACC
p4 <- ggplot(grand.mean2, 
       aes(x = factor(matchness), y = ACC, color = factor(label), group = factor(label))) +
  geom_line(position = position_dodge(0.6)) +
  geom_point(size = 3, position = position_dodge(0.6)) +
  labs(x = "match", y = "ACC") +
  geom_point(data = mean.plot2,
             aes(x = conds, y = ACC, group = factor(subj_idx)),
             position = position_dodge(0.06),
             alpha = 0.3) +
  geom_line(data = mean.plot2,
            aes(x = conds, y = ACC, group = factor(subj_idx)),
            position = position_dodge(0.06),
            linetype = 1,
            size = 0.8,
            color = "#000000",
            alpha = 0.05) +
  scale_color_manual(
    name = "label",
    labels = c("self", "friend", "stranger"),
    values = c("self" = "#b26d5d", "friend" = "#6b798e", "stranger" = "#7e527f")  
  ) +
  papaja::theme_apa()

p4
```

```{r}
p3 + p4 + 
  plot_layout(guides = 'collect')
```

# 3D
## 平面图
```{r}
# 转换 PDF (cohen_d) 为 CDF
df1 <- df1 %>%
  arrange(v, a, t) %>%  # 按坐标排序，确保 CDF 计算顺序
  mutate(cdf = cumsum(cohen_d) / sum(cohen_d))  # 累积和并归一化为 [0, 1]

# 设置颜色映射
# 创建从蓝色到红色的渐变色
color_palette <- colorRampPalette(c("blue", "purple", "red"))  # 更平滑的渐变
colors <- color_palette(100)[as.numeric(cut(df1$cdf, breaks = 100))]

# 使用 scatterplot3d 绘制 3D 散点图，颜色映射 CDF
s3d <- scatterplot3d(df1$v, df1$a, df1$t, color = colors,
                     pch = 16, xlab = "v", ylab = "a", zlab = "t")

# 为确保显示完整，添加所有点的坐标
s3d$points3d(df1$v, df1$a, df1$t, pch = 16, col = colors)

# 添加渐变色图注
par(xpd = TRUE)  # 允许在图的边界外绘制图注
color.legend(xl = 1.2, yb = 0.2, xr = 1.3, yt = 0.8, 
             legend = c("Low CDF", "High CDF"),   # 标签
             rect.col = color_palette(100),       # 渐变色
             gradient = "y")                      # 垂直方向渐变
```

```{r}
# 转换 PDF (cohen_d) 为 CDF
df1 <- df1 %>%
  arrange(NN, NT, NW) %>%  # 按坐标排序，确保 CDF 计算顺序
  mutate(cdf = cumsum(cohen_d) / sum(cohen_d))  # 累积和并归一化为 [0, 1]

# 设置颜色映射
# 创建从蓝色到红色的渐变色
color_palette <- colorRampPalette(c("blue", "purple", "red"))  # 更平滑的渐变
colors <- color_palette(100)[as.numeric(cut(df1$cdf, breaks = 100))]

# 使用 scatterplot3d 绘制 3D 散点图，颜色映射 CDF
s3d <- scatterplot3d(df1$NN, df1$NT, df1$NW, color = colors,
                     pch = 16, xlab = "N", ylab = "T", zlab = "W")

# 为确保显示完整，添加所有点的坐标
s3d$points3d(df1$NN, df1$NT, df1$NW, pch = 16, col = colors)

# 添加渐变色图注
par(xpd = TRUE)  # 允许在图的边界外绘制图注
color.legend(xl = 1.2, yb = 0.2, xr = 1.3, yt = 0.8, 
             legend = c("Low CDF", "High CDF"),   # 标签
             rect.col = color_palette(100),       # 渐变色
             gradient = "y")                      # 垂直方向渐变
```

```{r}
# 转换 PDF (cohen_d) 为 CDF
df1 <- df1 %>%
  arrange(N, W) %>%  # 按坐标排序，确保 CDF 计算顺序
  mutate(cdf = cumsum(cohen_d) / sum(cohen_d))  # 累积和并归一化为 [0, 1]

# 设置颜色映射
# 创建从蓝色到红色的渐变色
color_palette <- colorRampPalette(c("blue", "purple", "red"))  # 更平滑的渐变
colors <- color_palette(100)[as.numeric(cut(df1$cdf, breaks = 100))]

# 使用 scatterplot3d 绘制 3D 散点图，颜色映射 CDF
s3d <- scatterplot3d(df1$N, df1$W, df1$cohen_d, color = colors,
                     pch = 16, xlab = "N", ylab = "W", zlab = "Cohen's d")

# 为确保显示完整，添加所有点的坐标
s3d$points3d(df1$N, df1$W, df1$cohen_d, pch = 16, col = colors)

# 添加渐变色图注
par(xpd = TRUE)  # 允许在图的边界外绘制图注
color.legend(xl = 1.2, yb = 0.2, xr = 1.3, yt = 0.8, 
             legend = c("Low CDF", "High CDF"),   # 标签
             rect.col = color_palette(100),       # 渐变色
             gradient = "y")
```

```{r}
# 转换 PDF (cohen_d) 为 CDF
df1 <- df1 %>%
  arrange(N, T) %>%  # 按坐标排序，确保 CDF 计算顺序
  mutate(cdf = cumsum(cohen_d) / sum(cohen_d))  # 累积和并归一化为 [0, 1]

# 设置颜色映射
# 创建从蓝色到红色的渐变色
color_palette <- colorRampPalette(c("blue", "purple", "red"))  # 更平滑的渐变
colors <- color_palette(100)[as.numeric(cut(df1$cdf, breaks = 100))]

# 使用 scatterplot3d 绘制 3D 散点图，颜色映射 CDF
s3d <- scatterplot3d(df1$N, df1$T, df1$cohen_d, color = colors,
                     pch = 16, xlab = "N", ylab = "T", zlab = "Cohen's d")

# 为确保显示完整，添加所有点的坐标
s3d$points3d(df1$N, df1$T, df1$cohen_d, pch = 16, col = colors)

# 添加渐变色图注
par(xpd = TRUE)  # 允许在图的边界外绘制图注
color.legend(xl = 1.2, yb = 0.2, xr = 1.3, yt = 0.8, 
             legend = c("Low CDF", "High CDF"),   # 标签
             rect.col = color_palette(100),       # 渐变色
             gradient = "y")
```

```{r}
# 转换 PDF (cohen_d) 为 CDF
df1 <- df1 %>%
  arrange(W, T) %>%  # 按坐标排序，确保 CDF 计算顺序
  mutate(cdf = cumsum(cohen_d) / sum(cohen_d))  # 累积和并归一化为 [0, 1]

# 设置颜色映射
# 创建从蓝色到红色的渐变色
color_palette <- colorRampPalette(c("blue", "purple", "red"))  # 更平滑的渐变
colors <- color_palette(100)[as.numeric(cut(df1$cdf, breaks = 100))]

# 使用 scatterplot3d 绘制 3D 散点图，颜色映射 CDF
s3d <- scatterplot3d(df1$W, df1$T, df1$cohen_d, color = colors,
                     pch = 16, xlab = "W", ylab = "T", zlab = "Cohen's d")

# 为确保显示完整，添加所有点的坐标
s3d$points3d(df1$W, df1$T, df1$cohen_d, pch = 16, col = colors)

# 添加渐变色图注
par(xpd = TRUE)  # 允许在图的边界外绘制图注
color.legend(xl = 1.2, yb = 0.2, xr = 1.3, yt = 0.8, 
             legend = c("Low CDF", "High CDF"),   # 标签
             rect.col = color_palette(100),       # 渐变色
             gradient = "y")
```

## 可旋转
```{r}
# 转换 PDF (cohen_d) 为 CDF
df1 <- df1 %>%
  arrange(N, T, W) %>%  # 按坐标排序，确保 CDF 计算顺序
  mutate(cdf = cumsum(cohen_d) / sum(cohen_d))  # 累积和并归一化为 [0, 1]

# 设置颜色映射
color_palette <- colorRampPalette(c("blue", "purple", "red"))
colors <- color_palette(100)[as.numeric(cut(df1$cdf, breaks = 100))]

# 使用 plotly 绘制 3D 散点图
plot_ly(df1, x = ~N, y = ~T, z = ~W, color = ~cdf, colors = color_palette(100),
        type = 'scatter3d', mode = 'markers',
        marker = list(size = 5)) %>%
  layout(scene = list(xaxis = list(title = 'N'),
                      yaxis = list(title = 'T'),
                      zaxis = list(title = "W")),
         coloraxis = list(colorbar = list(title = "CDF"),
                          colorscale = color_palette(100)))
```

```{r}
# 转换 PDF (cohen_d) 为 CDF
df1 <- df1 %>%
  arrange(N, T) %>%  # 按坐标排序，确保 CDF 计算顺序
  mutate(cdf = cumsum(cohen_d) / sum(cohen_d))  # 累积和并归一化为 [0, 1]

# 设置颜色映射
color_palette <- colorRampPalette(c("blue", "purple", "red"))
colors <- color_palette(100)[as.numeric(cut(df1$cdf, breaks = 100))]

# 使用 plotly 绘制 3D 散点图
plot_ly(df1, x = ~N, y = ~T, z = ~cohen_d, color = ~cdf, colors = color_palette(100),
        type = 'scatter3d', mode = 'markers',
        marker = list(size = 5)) %>%
  layout(scene = list(xaxis = list(title = 'N'),
                      yaxis = list(title = 'T'),
                      zaxis = list(title = "Cohen's d")),
         coloraxis = list(colorbar = list(title = "CDF"),
                          colorscale = color_palette(100)))
```

```{r}
# 转换 PDF (cohen_d) 为 CDF
df1 <- df1 %>%
  arrange(N, W) %>%  # 按坐标排序，确保 CDF 计算顺序
  mutate(cdf = cumsum(cohen_d) / sum(cohen_d))  # 累积和并归一化为 [0, 1]

# 设置颜色映射
color_palette <- colorRampPalette(c("blue", "purple", "red"))
colors <- color_palette(100)[as.numeric(cut(df1$cdf, breaks = 100))]

# 使用 plotly 绘制 3D 散点图
plot_ly(df1, x = ~N, y = ~W, z = ~cohen_d, color = ~cdf, colors = color_palette(100),
        type = 'scatter3d', mode = 'markers',
        marker = list(size = 5)) %>%
  layout(scene = list(xaxis = list(title = 'N'),
                      yaxis = list(title = 'W'),
                      zaxis = list(title = "Cohen's d")),
         coloraxis = list(colorbar = list(title = "CDF"),
                          colorscale = color_palette(100)))
```

```{r}
# 转换 PDF (cohen_d) 为 CDF
df1 <- df1 %>%
  arrange(T, W) %>%  # 按坐标排序，确保 CDF 计算顺序
  mutate(cdf = cumsum(cohen_d) / sum(cohen_d))  # 累积和并归一化为 [0, 1]

# 设置颜色映射
color_palette <- colorRampPalette(c("blue", "purple", "red"))
colors <- color_palette(100)[as.numeric(cut(df1$cdf, breaks = 100))]

# 使用 plotly 绘制 3D 散点图
plot_ly(df1, x = ~T, y = ~W, z = ~cohen_d, color = ~cdf, colors = color_palette(100),
        type = 'scatter3d', mode = 'markers',
        marker = list(size = 5)) %>%
  layout(scene = list(xaxis = list(title = 'T'),
                      yaxis = list(title = 'W'),
                      zaxis = list(title = "Cohen's d")),
         coloraxis = list(colorbar = list(title = "CDF"),
                          colorscale = color_palette(100)))
```

# Visualization
```{r}
# 查看 cohen's d 的分布
ggplot(subj.mean1, aes(x = cohen_d)) + 
  geom_density(fill = "blue") +
  labs(title = "Distribution of Cohen's d")

# 查看参数 v、a的分布
ggplot(subj.mean1, aes(x = v)) + 
  geom_density(fill = "skyblue") + 
  labs(title = "Distribution of v")

ggplot(subj.mean1, aes(x = a)) + 
  geom_density(fill = "lightblue") + 
  labs(title = "Distribution of a")
```




# need to update
```{r}
df_diff <- mean1 %>%
  filter(matchness == "match") %>%
  group_by(subj_idx) %>%
  summarize(
    RT_diff = RT[label == "stranger"] - RT[label == "self"],
    N = first(N),
    T = first(T),
    W = first(W)) %>%
  ungroup()

modelx1 <- lm(RT_diff ~ N * T * W, 
              data = df_diff)
summary(modelx1)

modelx2 <- lm(RT_diff ~ N + T + W, 
              data = df_diff)
summary(modelx2)

modelx3 <- lm(RT_diff ~ N * T + W, 
              data = df_diff)
summary(modelx3)

modelx4 <- lm(RT_diff ~ N + T * W, 
              data = df_diff)
summary(modelx4)

performance::compare_performance(modelx1, modelx2, modelx3, modelx4, rank = TRUE, verbose = FALSE)
```

```{r}
table(df_diff$N, df_diff$W)
table(df_diff$T, df_diff$W)
table(df_diff$N, df_diff$T)
```


```{r}
# 不同的数据点太多了暂时做不了：生成10000个被试，分类画试试
library(ggplot2)
library(emmeans)
# 提高内存限制到 32GB（单位：字节，32GB = 32 × 1024^3 = 34359738368）
mem.maxVSize(34359738368)
install.packages("ggplot2")
# 提取数据集中 N、T 和 W 的所有唯一取值
n_values <- unique(df_diff$N)
t_values <- unique(df_diff$T)
w_values <- unique(df_diff$W)

# 使用 emmeans 计算不同 Practice_Number 水平下的 Response_Window 对 RT_diff 的效应
# 计算 N 和 T 不同水平下的边际均值
em_result_s2 <- emmeans(modelx3, ~ N | W,
                     at = list(N = n_values, 
                               W = w_values))

# 查看结果
summary(em_result_s2)

# 进行配对比较
pairs(em_result_s2)

# 将 emmeans 结果转换为数据框
em_df_s2 <- as.data.frame(em_result_s2)

ggplot(em_df_s2, aes(x = N, y = emmean, color = as.factor(W), group = W)) +
  geom_line() +            # 添加连线，显示不同 Response_Window 的变化趋势
  geom_point() +           # 添加点
  labs(x = "N", 
       y = "emmean", 
       color = "W") +
  theme_minimal()
```


## Parameter Recovery
```{r}
# 参数恢复：估计 v 和 a 的平均值
library(ggplot2)
estimated_params <- simulated_ddm_data %>%
  group_by(matchness, label) %>%
  summarise(mean_v = mean(v), mean_a = mean(a), .groups = 'drop')

raw_params <- print(unique(simulated_ddm_data[c("matchness", "label", "v", "a")]))

# 可视化原始参数和恢复参数的比较
ggplot(estimated_params, aes(x = label, y = mean_v, fill = matchness)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Recovered Parameter v", y = "Estimated v") +
  theme_minimal()

ggplot(estimated_params, aes(x = label, y = mean_a, fill = matchness)) +
  geom_bar(stat = "identity", position = position_dodge()) +
  labs(title = "Recovered Parameter a", y = "Estimated a") +
  theme_minimal()
```


## model
```{r}
##single
# N对rt的影响
plot(mean$n, mean$RT)
m1 <- lm(RT ~ n, data = mean)
summary(m1)

# W对rt的影响
plot(mean$W, mean$RT)
m2 <- lm(RT ~ W, data = mean)
summary(m2)

# T对rt的影响
plot(mean$T, mean$RT)
m3 <- lm(RT ~ T, data = mean)
summary(m3)
```


```{r}
##Multiple
# N, W, T对rt的影响
# 设置种子以确保结果的可重复性
set.seed(617)

# 随机选择70%的数据作为训练集，剩余的30%作为测试集
train_index <- caret::createDataPartition(df1$rt, p = 0.7, list = FALSE)
train_data <- df1[train_index, ]
test_data <- df1[-train_index, ]

# 根据训练集生成模型
library(lme4)    # 关键！加载混合效应模型包
library(caret)
library(dplyr)
model_full <- lmer(data = train_data,
                   formula = rt ~ N + W + T + (1|subj_idx))
summary(model_full)

# 使用模型进行预测
pre <- stats::predict(model_full, newdata = test_data)
test_data$pre <- pre

# 计算预测值与实际值之间的误差
errors <- test_data$rt - pre

# 计算RMSE，预测值与实际值之间误差的平方和的均值的平方根，反映了模型预测值的标准偏差
RMSE <- sqrt(mean(errors^2))

# 计算SSE (Sum of Squared Errors)
SSE <- sum(errors^2)

# 计算SST (Total Sum of Squares)
SST <- sum((test_data$rt - mean(test_data$rt))^2)

# 计算R²，表示模型拟合优度的指标，取值范围在0到1之间，越接近1表示模型拟合越好
R2 <- 1 - (SSE / SST)

# 计算模型的性能指标
performance <- c(RMSE, R2)

# 打印性能指标
print(performance)
```

```{r}
# 绘制实际值与预测值的散点图
ggplot(test_data, aes(x = rt, y = pre)) +
  geom_point(alpha = 0.1) +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed", color = "red") + # 添加y=x的参考线
  labs(x = "Actual RT", y = "Predicted RT", 
       title = "Actual vs Predicted Reaction Times") +
  papaja::theme_apa()
```

```{r}
# 设置种子以确保结果的可重复性
set.seed(617)

# 定义要调优的参数空间
param_grid <- expand.grid(
  N = seq(1, 100, by = 5),  # 假设N的范围是1到100，步长为1
  W = seq(200, 6000, by = 200),  # 假设W的范围是200到6000，步长为50
  T = seq(200, 1500, by = 200)   # 假设T的范围是200到1500，步长为50
)

# 创建交叉验证的索引（此处简化为直接使用部分数据作为训练集）
train_index <- sample(nrow(df1), 0.7 * nrow(df1))  # 70% 的数据作为训练集
train_data <- df1[train_index, ]
test_data <- df1[-train_index, ]

# 定义预处理方法，这里选择尺度缩放（scaling）
preproc <- preProcess(train_data[, c("N", "T", "W")], method = c("scale"))

# 检查 preproc 对象，确保其包含了均值和标准差
scaled_means <- preproc$mean
scaled_sds <- preproc$std

print(c(scaled_means, scaled_sds))

# 应用预处理到训练集和测试集
train_data_scaled <- predict(preproc, train_data)
test_data_scaled <- predict(preproc, test_data)

# 存储最佳模型和性能指标
best_model <- NULL
best_performance <- Inf

# 手动循环网格搜索寻找模型表现最优的NWT组合
for (i in 1:nrow(param_grid)) {
  N <- param_grid$N[i]
  W <- param_grid$W[i]
  T <- param_grid$T[i]
  
  # 训练模型
  model <- lmer(rt ~ N + W + T + (1|subj_idx), data = train_data_scaled)
  
  # 使用模型进行预测
  pre <- predict(model, newdata = test_data_scaled)
  
  # 计算RMSE
  RMSE <- sqrt(mean((test_data_scaled$rt - pre)^2))
  
  # 如果找到更好的模型，则更新模型性能指标
  if (RMSE < best_performance) {
    best_performance <- RMSE
    best_model <- model
  }
}

# 查看最佳模型和性能指标
print(c(best_model, best_performance))

# 将训练集和测试集中的 N、W、T 转换回原始尺度，x original = x scaled * sd + mean


# best_model_original就是在原始数据尺度上的最佳模型
# 获取尺度缩放后的均值和标准差
# scaled_means <- preproc$mean
# scaled_sds <- preproc$std

# 获取模型的系数和截距
# coefficients_scaled <- coef(best_model)
# intercept_scaled <- fixef(best_model)

# 根据尺度缩放的方式进行系数和截距的转换
# coefficients_original <- coefficients_scaled * scaled_sds / scaled_sds
# intercept_original <- intercept_scaled - sum(coefficients_scaled * scaled_means / scaled_sds)

# 创建一个新的模型对象，使用原始数据尺度的系数和截距
# best_model_original <- best_model
# coef(best_model_original) <- coefficients_original
# fixef(best_model_original) <- intercept_original
```

